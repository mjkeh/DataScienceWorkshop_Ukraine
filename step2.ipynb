{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa6fb723",
   "metadata": {},
   "source": [
    "# Data Science for Social Justice Workshop Group Project: Ukraine\n",
    "\n",
    "## 1. Preprocessing (MinJee & Nazmul)\n",
    "\n",
    "## 1-1. Importing Data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "633ae39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\moren\\\\OneDrive\\\\Documents\\\\Third Year\\\\Summer 22\\\\Data Science\\\\Data-Science-Social-Justice-main\\\\Project'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd ##it will be different for all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b573b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d24201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../data') ##it will be different for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "094173d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77598832",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('submissions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d64ab2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88764, 18)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a98ca61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of             idint      idstr     created  self  nsfw             author  \\\n",
       "0        13054757   t3_7rt45  1232688225     0     0        nikitos2009   \n",
       "1        13072291   t3_7s6n7  1232834472     1     0              OlehM   \n",
       "2        13093545   t3_7sn1l  1233019738     0     0        nikitos2009   \n",
       "3        13118896   t3_7t6ls  1233182615     0     0        nikitos2009   \n",
       "4        13238506   t3_7vqwa  1234081946     0     0         ger4antche   \n",
       "...           ...        ...         ...   ...   ...                ...   \n",
       "88759  1773259914  t3_tbr43u  1647008288     0     0      Daniel_Poirot   \n",
       "88760  1773261780  t3_tbr5jo  1647008406     1     0             De-nis   \n",
       "88761  1773263139  t3_tbr6lf  1647008495     1     0  vonschlieffenflan   \n",
       "88762  1773264367  t3_tbr7jj  1647008572     0     0             Regrup   \n",
       "88763  1773265764  t3_tbr8mc  1647008667     0     0        palcemvglaz   \n",
       "\n",
       "                                                   title  \\\n",
       "0                   Лучший политический ресурс в Украине   \n",
       "1                                                     Dr   \n",
       "2               Основы гармонии украинства с московством   \n",
       "3      Служба Бандеризации Украины выясняет кто убил ...   \n",
       "4                                     amzek.blogspot.com   \n",
       "...                                                  ...   \n",
       "88759  Is there anything wrong with supporting nation...   \n",
       "88760                           Russia blocked Instagram   \n",
       "88761  Doesn’t the lack of direct response from NATO ...   \n",
       "88762  DESTROYED ruZZian Commander of the 29th Army o...   \n",
       "88763             Zelenskiy, 16 day of war, with En Subs   \n",
       "\n",
       "                                                     url  \\\n",
       "0                                   http://pepper.at.ua/   \n",
       "1                                                    NaN   \n",
       "2                      http://pepper.at.ua/publ/8-1-0-30   \n",
       "3                      http://pepper.at.ua/publ/8-1-0-34   \n",
       "4                              http://amzek.blogspot.com   \n",
       "...                                                  ...   \n",
       "88759  https://www.oxfordlearnersdictionaries.com/def...   \n",
       "88760                                                NaN   \n",
       "88761                                                NaN   \n",
       "88762                https://i.redd.it/gnlst2lfkrm81.jpg   \n",
       "88763                    https://v.redd.it/7xgiuqrtkrm81   \n",
       "\n",
       "                                                selftext  score subreddit  \\\n",
       "0                                                    NaN      0   ukraine   \n",
       "1                                              [removed]      1   ukraine   \n",
       "2                                                    NaN      1   ukraine   \n",
       "3                                                    NaN      1   ukraine   \n",
       "4                                                    NaN      0   ukraine   \n",
       "...                                                  ...    ...       ...   \n",
       "88759                                                NaN      1   ukraine   \n",
       "88760                                          [removed]      1   ukraine   \n",
       "88761  What is the argument that people are using aga...      3   ukraine   \n",
       "88762                                                NaN     22   ukraine   \n",
       "88763                                                NaN      1   ukraine   \n",
       "\n",
       "      distinguish  textlen  num_comments                flair_text  \\\n",
       "0             NaN        0             0                       NaN   \n",
       "1             NaN        9             0                       NaN   \n",
       "2             NaN        0             0                       NaN   \n",
       "3             NaN        0             0                       NaN   \n",
       "4             NaN        0             1                       NaN   \n",
       "...           ...      ...           ...                       ...   \n",
       "88759         NaN        0             0                Discussion   \n",
       "88760         NaN        0             0                      News   \n",
       "88761         NaN       70             7                Discussion   \n",
       "88762         NaN        0             2                       WAR   \n",
       "88763         NaN        0             0  Government (Unconfirmed)   \n",
       "\n",
       "      flair_css_class  augmented_at  augmented_count  \n",
       "0                 NaN           NaN              NaN  \n",
       "1                 NaN           NaN              NaN  \n",
       "2                 NaN           NaN              NaN  \n",
       "3                 NaN           NaN              NaN  \n",
       "4                 NaN           NaN              NaN  \n",
       "...               ...           ...              ...  \n",
       "88759             NaN           NaN              NaN  \n",
       "88760    ukraine-news           NaN              NaN  \n",
       "88761             NaN           NaN              NaN  \n",
       "88762             war           NaN              NaN  \n",
       "88763             NaN           NaN              NaN  \n",
       "\n",
       "[88764 rows x 18 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e1839b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88764, 18)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "122b3f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['idint',\n",
       " 'idstr',\n",
       " 'created',\n",
       " 'self',\n",
       " 'nsfw',\n",
       " 'author',\n",
       " 'title',\n",
       " 'url',\n",
       " 'selftext',\n",
       " 'score',\n",
       " 'subreddit',\n",
       " 'distinguish',\n",
       " 'textlen',\n",
       " 'num_comments',\n",
       " 'flair_text',\n",
       " 'flair_css_class',\n",
       " 'augmented_at',\n",
       " 'augmented_count']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75c1a94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idint</th>\n",
       "      <th>idstr</th>\n",
       "      <th>created</th>\n",
       "      <th>self</th>\n",
       "      <th>nsfw</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>distinguish</th>\n",
       "      <th>textlen</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>flair_text</th>\n",
       "      <th>flair_css_class</th>\n",
       "      <th>augmented_at</th>\n",
       "      <th>augmented_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13054757</td>\n",
       "      <td>t3_7rt45</td>\n",
       "      <td>1232688225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nikitos2009</td>\n",
       "      <td>Лучший политический ресурс в Украине</td>\n",
       "      <td>http://pepper.at.ua/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13072291</td>\n",
       "      <td>t3_7s6n7</td>\n",
       "      <td>1232834472</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>OlehM</td>\n",
       "      <td>Dr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13093545</td>\n",
       "      <td>t3_7sn1l</td>\n",
       "      <td>1233019738</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nikitos2009</td>\n",
       "      <td>Основы гармонии украинства с московством</td>\n",
       "      <td>http://pepper.at.ua/publ/8-1-0-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13118896</td>\n",
       "      <td>t3_7t6ls</td>\n",
       "      <td>1233182615</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nikitos2009</td>\n",
       "      <td>Служба Бандеризации Украины выясняет кто убил ...</td>\n",
       "      <td>http://pepper.at.ua/publ/8-1-0-34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13238506</td>\n",
       "      <td>t3_7vqwa</td>\n",
       "      <td>1234081946</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ger4antche</td>\n",
       "      <td>amzek.blogspot.com</td>\n",
       "      <td>http://amzek.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      idint     idstr     created  self  nsfw       author  \\\n",
       "0  13054757  t3_7rt45  1232688225     0     0  nikitos2009   \n",
       "1  13072291  t3_7s6n7  1232834472     1     0        OlehM   \n",
       "2  13093545  t3_7sn1l  1233019738     0     0  nikitos2009   \n",
       "3  13118896  t3_7t6ls  1233182615     0     0  nikitos2009   \n",
       "4  13238506  t3_7vqwa  1234081946     0     0   ger4antche   \n",
       "\n",
       "                                               title  \\\n",
       "0               Лучший политический ресурс в Украине   \n",
       "1                                                 Dr   \n",
       "2           Основы гармонии украинства с московством   \n",
       "3  Служба Бандеризации Украины выясняет кто убил ...   \n",
       "4                                 amzek.blogspot.com   \n",
       "\n",
       "                                 url   selftext  score subreddit distinguish  \\\n",
       "0               http://pepper.at.ua/        NaN      0   ukraine         NaN   \n",
       "1                                NaN  [removed]      1   ukraine         NaN   \n",
       "2  http://pepper.at.ua/publ/8-1-0-30        NaN      1   ukraine         NaN   \n",
       "3  http://pepper.at.ua/publ/8-1-0-34        NaN      1   ukraine         NaN   \n",
       "4          http://amzek.blogspot.com        NaN      0   ukraine         NaN   \n",
       "\n",
       "   textlen  num_comments flair_text flair_css_class  augmented_at  \\\n",
       "0        0             0        NaN             NaN           NaN   \n",
       "1        9             0        NaN             NaN           NaN   \n",
       "2        0             0        NaN             NaN           NaN   \n",
       "3        0             0        NaN             NaN           NaN   \n",
       "4        0             1        NaN             NaN           NaN   \n",
       "\n",
       "   augmented_count  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25380323",
   "metadata": {},
   "source": [
    "## 1-2. Dropping Columns and Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cd323b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idint</th>\n",
       "      <th>idstr</th>\n",
       "      <th>created</th>\n",
       "      <th>nsfw</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>distinguish</th>\n",
       "      <th>textlen</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>flair_text</th>\n",
       "      <th>flair_css_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13054757</td>\n",
       "      <td>t3_7rt45</td>\n",
       "      <td>1232688225</td>\n",
       "      <td>0</td>\n",
       "      <td>nikitos2009</td>\n",
       "      <td>Лучший политический ресурс в Украине</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13072291</td>\n",
       "      <td>t3_7s6n7</td>\n",
       "      <td>1232834472</td>\n",
       "      <td>0</td>\n",
       "      <td>OlehM</td>\n",
       "      <td>Dr</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13093545</td>\n",
       "      <td>t3_7sn1l</td>\n",
       "      <td>1233019738</td>\n",
       "      <td>0</td>\n",
       "      <td>nikitos2009</td>\n",
       "      <td>Основы гармонии украинства с московством</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13118896</td>\n",
       "      <td>t3_7t6ls</td>\n",
       "      <td>1233182615</td>\n",
       "      <td>0</td>\n",
       "      <td>nikitos2009</td>\n",
       "      <td>Служба Бандеризации Украины выясняет кто убил ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13238506</td>\n",
       "      <td>t3_7vqwa</td>\n",
       "      <td>1234081946</td>\n",
       "      <td>0</td>\n",
       "      <td>ger4antche</td>\n",
       "      <td>amzek.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      idint     idstr     created  nsfw       author  \\\n",
       "0  13054757  t3_7rt45  1232688225     0  nikitos2009   \n",
       "1  13072291  t3_7s6n7  1232834472     0        OlehM   \n",
       "2  13093545  t3_7sn1l  1233019738     0  nikitos2009   \n",
       "3  13118896  t3_7t6ls  1233182615     0  nikitos2009   \n",
       "4  13238506  t3_7vqwa  1234081946     0   ger4antche   \n",
       "\n",
       "                                               title   selftext  score  \\\n",
       "0               Лучший политический ресурс в Украине        NaN      0   \n",
       "1                                                 Dr  [removed]      1   \n",
       "2           Основы гармонии украинства с московством        NaN      1   \n",
       "3  Служба Бандеризации Украины выясняет кто убил ...        NaN      1   \n",
       "4                                 amzek.blogspot.com        NaN      0   \n",
       "\n",
       "  distinguish  textlen  num_comments flair_text flair_css_class  \n",
       "0         NaN        0             0        NaN             NaN  \n",
       "1         NaN        9             0        NaN             NaN  \n",
       "2         NaN        0             0        NaN             NaN  \n",
       "3         NaN        0             0        NaN             NaN  \n",
       "4         NaN        0             1        NaN             NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##remove some columns that we are not going to use\n",
    "\n",
    "df = df.drop(['self', 'url', 'subreddit', 'augmented_at', 'augmented_count'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79d323f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73414, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##get rid of posts that have been deleted/removed\n",
    "\n",
    "df = df.loc[~df['selftext'].isin(['[removed]', '[deleted]' ]),:]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27b9d953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16665, 13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## drop null values\n",
    "df = df.dropna(subset=['selftext'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7cbc166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idint</th>\n",
       "      <th>idstr</th>\n",
       "      <th>created</th>\n",
       "      <th>nsfw</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>distinguish</th>\n",
       "      <th>textlen</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>flair_text</th>\n",
       "      <th>flair_css_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>26781072</td>\n",
       "      <td>t3_fy0eo</td>\n",
       "      <td>1299351508</td>\n",
       "      <td>0</td>\n",
       "      <td>margys</td>\n",
       "      <td>Мам, а когда я выросту, ты постареешь?...</td>\n",
       "      <td>Сегодня моя золотая птичка снова задалась вопр...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>26795140</td>\n",
       "      <td>t3_fyb9g</td>\n",
       "      <td>1299397232</td>\n",
       "      <td>0</td>\n",
       "      <td>pozhaluista</td>\n",
       "      <td>Does the /r/ Ukraine have anyone here? Hello?</td>\n",
       "      <td>Seems quiet.</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>29482904</td>\n",
       "      <td>t3_hjx5k</td>\n",
       "      <td>1306343697</td>\n",
       "      <td>0</td>\n",
       "      <td>visarun</td>\n",
       "      <td>Does immigration in Simferpol check whether th...</td>\n",
       "      <td>I have stayed 70 days and then 80 days out of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>29608809</td>\n",
       "      <td>t3_hmmax</td>\n",
       "      <td>1306639850</td>\n",
       "      <td>0</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>Tickets to Ukraine from Seoul?</td>\n",
       "      <td>Hi everyone.  I'd like to visit Ukraine for th...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>281</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>33263382</td>\n",
       "      <td>t3_jsy6u</td>\n",
       "      <td>1314200067</td>\n",
       "      <td>0</td>\n",
       "      <td>lsakbaetle3r9</td>\n",
       "      <td>looking for someone</td>\n",
       "      <td>had a friend who moved to my town ~4-5 years a...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>386</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       idint     idstr     created  nsfw         author  \\\n",
       "35  26781072  t3_fy0eo  1299351508     0         margys   \n",
       "36  26795140  t3_fyb9g  1299397232     0    pozhaluista   \n",
       "50  29482904  t3_hjx5k  1306343697     0        visarun   \n",
       "51  29608809  t3_hmmax  1306639850     0      [deleted]   \n",
       "62  33263382  t3_jsy6u  1314200067     0  lsakbaetle3r9   \n",
       "\n",
       "                                                title  \\\n",
       "35         Мам, а когда я выросту, ты постареешь?...    \n",
       "36      Does the /r/ Ukraine have anyone here? Hello?   \n",
       "50  Does immigration in Simferpol check whether th...   \n",
       "51                     Tickets to Ukraine from Seoul?   \n",
       "62                                looking for someone   \n",
       "\n",
       "                                             selftext  score distinguish  \\\n",
       "35  Сегодня моя золотая птичка снова задалась вопр...      0         NaN   \n",
       "36                                      Seems quiet.      10         NaN   \n",
       "50  I have stayed 70 days and then 80 days out of ...      0         NaN   \n",
       "51  Hi everyone.  I'd like to visit Ukraine for th...      2         NaN   \n",
       "62  had a friend who moved to my town ~4-5 years a...      3         NaN   \n",
       "\n",
       "    textlen  num_comments flair_text flair_css_class  \n",
       "35      204             0        NaN             NaN  \n",
       "36       13            24        NaN             NaN  \n",
       "50      223             1        NaN             NaN  \n",
       "51      281             0        NaN             NaN  \n",
       "62      386             1        NaN             NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a53e535",
   "metadata": {},
   "source": [
    "## 1-3. Cleaning Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a8c1bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\moren\\anaconda3\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy) (61.2.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy) (0.7.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy) (2.4.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy) (1.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy) (8.0.17)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\moren\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Collecting en-core-web-sm==3.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.3.0) (3.3.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.6.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.27.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (21.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (61.2.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.21.5)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.64.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.17)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.11.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.1.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\moren\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cba8128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spaCy\n",
    "import spacy\n",
    "# Load the English preprocessing pipeline\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26bae3de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сегодня моя золотая птичка снова задалась вопросом... \"Мам, а когда я выросту, ты постареешь?... а потом умрешь? ... и папа?... Мамочка, я не хочу взрослеть, можно я навсегда останусь такой маленькой?...\"\n"
     ]
    }
   ],
   "source": [
    "# Test: Parse the first reddit post in the dataset\n",
    "parsed_post = nlp(df.selftext.iloc[0])\n",
    "print(parsed_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80988f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1\n",
      "Сегодня моя золотая птичка снова задалась вопросом...\n",
      "\n",
      "Sentence 2\n",
      "\"Мам, а когда я выросту, ты постареешь?...\n",
      "\n",
      "Sentence 3\n",
      "а потом умрешь? ...\n",
      "\n",
      "Sentence 4\n",
      "и папа?...\n",
      "\n",
      "Sentence 5\n",
      "Мамочка, я не хочу взрослеть, можно я навсегда останусь такой маленькой?...\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print each sentence in the parsed post\n",
    "for idx, sentence in enumerate(parsed_post.sents):  \n",
    "    ##In python, .sents is used for \"sentence segmentation\" which is present inside spacy. \n",
    "    print(f'Sentence {idx + 1}')\n",
    "    print(sentence)\n",
    "    print('') #space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2814f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_text</th>\n",
       "      <th>part_of_speech</th>\n",
       "      <th>token_lemma</th>\n",
       "      <th>token_stop</th>\n",
       "      <th>token_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Сегодня</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Сегодня</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>моя</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>моя</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>золотая</td>\n",
       "      <td>VERB</td>\n",
       "      <td>золотая</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>птичка</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>птичка</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>снова</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>снова</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>задалась</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>задалась</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>вопросом</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>вопросом</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>...</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>\"</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Мам</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Мам</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>а</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>а</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>когда</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>когда</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>я</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>я</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>выросту</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>выросту</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token_text part_of_speech token_lemma  token_stop  token_punct\n",
       "0     Сегодня          PROPN     Сегодня       False        False\n",
       "1         моя           NOUN         моя       False        False\n",
       "2     золотая           VERB     золотая       False        False\n",
       "3      птичка          PROPN      птичка       False        False\n",
       "4       снова          PROPN       снова       False        False\n",
       "5    задалась          PROPN    задалась       False        False\n",
       "6    вопросом          PROPN    вопросом       False        False\n",
       "7         ...          PUNCT         ...       False         True\n",
       "8           \"          PUNCT           \"       False         True\n",
       "9         Мам          PROPN         Мам       False        False\n",
       "10          ,          PUNCT           ,       False         True\n",
       "11          а          PROPN           а       False        False\n",
       "12      когда          PROPN       когда       False        False\n",
       "13          я          PROPN           я       False        False\n",
       "14    выросту          PROPN     выросту       False        False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the first 15 items for the following properties of the parsed post\n",
    "\n",
    "# The token text \n",
    "token_text = [token.orth_ for token in parsed_post][:15]   \n",
    "# Part of speech \n",
    "token_pos = [token.pos_ for token in parsed_post][:15]   \n",
    "# Lemma (or 'dictionary form')\n",
    "token_lemma = [token.lemma_ for token in parsed_post][:15]\n",
    "# Stop word? t/f\n",
    "token_stop = [token.is_stop for token in parsed_post][:15]\n",
    "# Puncutation? t/f\n",
    "token_punct = [token.is_punct for token in parsed_post][:15]\n",
    "\n",
    "# Make a dataframe with these items\n",
    "pd.DataFrame(zip(token_text, token_pos, token_lemma, token_stop, token_punct),\n",
    "             columns=['token_text', 'part_of_speech', 'token_lemma', 'token_stop', 'token_punct'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfa31d7",
   "metadata": {},
   "source": [
    "## Note: we need to apply nlp to all rows; I found this resource\n",
    "\n",
    "https://towardsdatascience.com/structured-natural-language-processing-with-pandas-and-spacy-7089e66d2b10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43550158",
   "metadata": {},
   "outputs": [],
   "source": [
    "##we need to apply nlp to all rows\n",
    "docs = list(nlp.pipe(df.selftext)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbdc720",
   "metadata": {},
   "source": [
    "## Q. The code above takes too long... what should we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a3cb543",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.doc.Doc' object has no attribute 'orth_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Extract the first 15 items for the following properties of the parsed docs\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# The token text \u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m token_text \u001b[38;5;241m=\u001b[39m [token\u001b[38;5;241m.\u001b[39morth_ \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m docs][:\u001b[38;5;241m15\u001b[39m]   \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Part of speech \u001b[39;00m\n\u001b[0;32m      6\u001b[0m token_pos \u001b[38;5;241m=\u001b[39m [token\u001b[38;5;241m.\u001b[39mpos_ \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m docs][:\u001b[38;5;241m15\u001b[39m]   \n",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Extract the first 15 items for the following properties of the parsed docs\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# The token text \u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m token_text \u001b[38;5;241m=\u001b[39m [\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morth_\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m docs][:\u001b[38;5;241m15\u001b[39m]   \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Part of speech \u001b[39;00m\n\u001b[0;32m      6\u001b[0m token_pos \u001b[38;5;241m=\u001b[39m [token\u001b[38;5;241m.\u001b[39mpos_ \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m docs][:\u001b[38;5;241m15\u001b[39m]   \n",
      "\u001b[1;31mAttributeError\u001b[0m: 'spacy.tokens.doc.Doc' object has no attribute 'orth_'"
     ]
    }
   ],
   "source": [
    "# Extract the first 15 items for the following properties of the parsed docs\n",
    "\n",
    "# The token text \n",
    "token_text = [token.orth_ for token in docs][:15]   \n",
    "# Part of speech \n",
    "token_pos = [token.pos_ for token in docs][:15]   \n",
    "# Lemma (or 'dictionary form')\n",
    "token_lemma = [token.lemma_ for token in docs][:15]\n",
    "# Stop word? t/f\n",
    "token_stop = [token.is_stop for token in docs][:15]\n",
    "# Puncutation? t/f\n",
    "token_punct = [token.is_punct for token in docs][:15]\n",
    "\n",
    "# Make a dataframe with these items\n",
    "pd.DataFrame(zip(token_text, token_pos, token_lemma, token_stop, token_punct),\n",
    "             columns=['token_text', 'part_of_speech', 'token_lemma', 'token_stop', 'token_punct'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99f3d87",
   "metadata": {},
   "source": [
    "## Note: We need to define lemmas\n",
    "From noteboook 01_preposession from line 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579afbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(token):\n",
    "    \"\"\"Helper function that specifies whether a token is:\n",
    "        - punctuation\n",
    "        - space\n",
    "        - digit\n",
    "    \"\"\"\n",
    "    return token.is_punct or token.is_space or token.is_digit\n",
    "\n",
    "def line_read(df, text_col='selftext'):\n",
    "    \"\"\"Generator function to read in text from df and get rid of line breaks.\"\"\"    \n",
    "    for text in df[text_col]:\n",
    "        yield text.replace('\\n', '')\n",
    "\n",
    "def preprocess(df, text_col='selftext', allowed_postags=['NOUN', 'ADJ']):\n",
    "    \"\"\"Preprocessing function to apply to a dataframe.\"\"\"\n",
    "    for parsed in nlp.pipe(line_read(df, text_col), batch_size=1000, disable=[\"tok2vec\", \"ner\"]):\n",
    "        # Gather lowercased, lemmatized tokens\n",
    "        tokens = [token.lemma_.lower() if token.lemma_ != '-PRON-'\n",
    "                  else token.lower_ \n",
    "                  for token in parsed if not clean(token)]\n",
    "        # Remove specific lemmatizations, and words that are not nouns or adjectives\n",
    "        tokens = [lemma\n",
    "                  for lemma in tokens\n",
    "                  if not lemma in [\"'s\",  \"’s\", \"’\"] and not lemma in allowed_postags]\n",
    "        # Remove stop words\n",
    "        tokens = [token for token in tokens if token not in spacy.lang.en.stop_words.STOP_WORDS]\n",
    "        yield tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd64956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This may take a while\n",
    "lemmas = [line for line in preprocess(df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227b5bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535b5a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(lemmas)\n",
    "len(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94694367",
   "metadata": {},
   "source": [
    "## Notes: We also might need bigram and trigram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e867ed5",
   "metadata": {},
   "source": [
    "## 2 Exploring Texts (Arlyn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4ce8c9",
   "metadata": {},
   "source": [
    "## 2.1 Diving Deeper into `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7a4bffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idint</th>\n",
       "      <th>idstr</th>\n",
       "      <th>created</th>\n",
       "      <th>nsfw</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>distinguish</th>\n",
       "      <th>textlen</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>flair_text</th>\n",
       "      <th>flair_css_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>26781072</td>\n",
       "      <td>t3_fy0eo</td>\n",
       "      <td>1299351508</td>\n",
       "      <td>0</td>\n",
       "      <td>margys</td>\n",
       "      <td>Мам, а когда я выросту, ты постареешь?...</td>\n",
       "      <td>Сегодня моя золотая птичка снова задалась вопр...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>26795140</td>\n",
       "      <td>t3_fyb9g</td>\n",
       "      <td>1299397232</td>\n",
       "      <td>0</td>\n",
       "      <td>pozhaluista</td>\n",
       "      <td>Does the /r/ Ukraine have anyone here? Hello?</td>\n",
       "      <td>Seems quiet.</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>29482904</td>\n",
       "      <td>t3_hjx5k</td>\n",
       "      <td>1306343697</td>\n",
       "      <td>0</td>\n",
       "      <td>visarun</td>\n",
       "      <td>Does immigration in Simferpol check whether th...</td>\n",
       "      <td>I have stayed 70 days and then 80 days out of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       idint     idstr     created  nsfw       author  \\\n",
       "35  26781072  t3_fy0eo  1299351508     0       margys   \n",
       "36  26795140  t3_fyb9g  1299397232     0  pozhaluista   \n",
       "50  29482904  t3_hjx5k  1306343697     0      visarun   \n",
       "\n",
       "                                                title  \\\n",
       "35         Мам, а когда я выросту, ты постареешь?...    \n",
       "36      Does the /r/ Ukraine have anyone here? Hello?   \n",
       "50  Does immigration in Simferpol check whether th...   \n",
       "\n",
       "                                             selftext  score distinguish  \\\n",
       "35  Сегодня моя золотая птичка снова задалась вопр...      0         NaN   \n",
       "36                                      Seems quiet.      10         NaN   \n",
       "50  I have stayed 70 days and then 80 days out of ...      0         NaN   \n",
       "\n",
       "    textlen  num_comments flair_text flair_css_class  \n",
       "35      204             0        NaN             NaN  \n",
       "36       13            24        NaN             NaN  \n",
       "50      223             1        NaN             NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9f2dfc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idint</th>\n",
       "      <th>idstr</th>\n",
       "      <th>created</th>\n",
       "      <th>nsfw</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>distinguish</th>\n",
       "      <th>textlen</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>flair_text</th>\n",
       "      <th>flair_css_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45587</th>\n",
       "      <td>1757241133</td>\n",
       "      <td>t3_t27rxp</td>\n",
       "      <td>1645911562</td>\n",
       "      <td>0</td>\n",
       "      <td>Ghost1069</td>\n",
       "      <td>Officials in Ukraine are doing their best to s...</td>\n",
       "      <td>-- EDIT FOR SUMY --- AIR RAID ON SUMY --- \\n\\n...</td>\n",
       "      <td>164624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31096</th>\n",
       "      <td>1753516706</td>\n",
       "      <td>t3_szzy5e</td>\n",
       "      <td>1645671618</td>\n",
       "      <td>0</td>\n",
       "      <td>soff_mm</td>\n",
       "      <td>It is an honor to be a Ukrainian at this hour.</td>\n",
       "      <td>We're staying strong. Support the Armed Forces...</td>\n",
       "      <td>48955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "      <td>2154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77784</th>\n",
       "      <td>1766534572</td>\n",
       "      <td>t3_t7qyss</td>\n",
       "      <td>1646540863</td>\n",
       "      <td>0</td>\n",
       "      <td>sharag123</td>\n",
       "      <td>It is almost 7am and the Sun has Risen on the ...</td>\n",
       "      <td>&amp;#x200B;</td>\n",
       "      <td>33895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>531</td>\n",
       "      <td>WAR</td>\n",
       "      <td>war</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            idint      idstr     created  nsfw     author  \\\n",
       "45587  1757241133  t3_t27rxp  1645911562     0  Ghost1069   \n",
       "31096  1753516706  t3_szzy5e  1645671618     0    soff_mm   \n",
       "77784  1766534572  t3_t7qyss  1646540863     0  sharag123   \n",
       "\n",
       "                                                   title  \\\n",
       "45587  Officials in Ukraine are doing their best to s...   \n",
       "31096     It is an honor to be a Ukrainian at this hour.   \n",
       "77784  It is almost 7am and the Sun has Risen on the ...   \n",
       "\n",
       "                                                selftext   score distinguish  \\\n",
       "45587  -- EDIT FOR SUMY --- AIR RAID ON SUMY --- \\n\\n...  164624         NaN   \n",
       "31096  We're staying strong. Support the Armed Forces...   48955         NaN   \n",
       "77784                                           &#x200B;   33895         NaN   \n",
       "\n",
       "       textlen  num_comments flair_text flair_css_class  \n",
       "45587        0          3099        NaN             NaN  \n",
       "31096       66          2154        NaN             NaN  \n",
       "77784       39           531        WAR             war  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort dataframe by highest scores\n",
    "df.sort_values(by=['score'], ascending=False)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7b7120d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows with a score higher than 500\n",
    "df_top = df.loc[df['score'] >= 500, :]\n",
    "len(df_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d86ae430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Russian-Ukrainian War       1992\n",
       "Question                    1382\n",
       "Discussion                  1229\n",
       "News                         393\n",
       "Request                      262\n",
       "WAR                          205\n",
       "Travel                       181\n",
       "Military                     119\n",
       "History                       70\n",
       "Media                         70\n",
       "Social Media                  69\n",
       "Humor                         63\n",
       "Russo-Ukrainian War           59\n",
       "Moving to Ukraine             43\n",
       "Music                         38\n",
       "WAR CRIME                     30\n",
       "Shitpost                      30\n",
       "War Crimes                    24\n",
       "Cuisine                       16\n",
       "Russian Protest               15\n",
       "Important                     14\n",
       "Video                         12\n",
       "Social media                  10\n",
       "Photo                         10\n",
       "Government (Unconfirmed)       7\n",
       "Tweet                          4\n",
       "Unconfirmed                    3\n",
       "Need help                      3\n",
       "WAR | Misleading               1\n",
       "Goverment (Unconfirmed)        1\n",
       "RATE MY BORSHCH!               1\n",
       ":FlagUA: Government            1\n",
       "Misleading                     1\n",
       "ASTARTES                       1\n",
       "Help                           1\n",
       "Name: flair_text, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique value counts for a column\n",
    "df.flair_text.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b181f90",
   "metadata": {},
   "source": [
    "## 2.2 Type-token ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6dfe8821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the TTR\n",
    "\n",
    "def type_token_ratio(tokens):\n",
    "    \"\"\"Calculates type-token ratio on tokens.\"\"\"\n",
    "    numTokens = len(tokens)\n",
    "    numTypes = len(set(tokens))\n",
    "    return numTypes / numTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3ce8bc",
   "metadata": {},
   "source": [
    "## Q. The code below is not working. I think is because we need to get the lemmas defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78afbd1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'lemmas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'lemmas'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#loop over the first 10 lemmatized submissions into dataframe\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlemmas\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[:\u001b[38;5;241m10\u001b[39m]:\n\u001b[0;32m      4\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39msplit()\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, text)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'lemmas'"
     ]
    }
   ],
   "source": [
    "#loop over the first 10 lemmatized submissions into dataframe\n",
    "\n",
    "for text in df['lemmas'][:10]:\n",
    "    tokens = text.split()\n",
    "    print('Text:\\n', text)\n",
    "    print('TTR:', type_token_ratio(tokens), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a59088a",
   "metadata": {},
   "source": [
    "## 2.3 Processing and Analyzing Language with `Text()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00f004ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\moren\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\moren\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\moren\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\moren\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\moren\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\moren\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "# Run if you do not have nltk installed\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7412af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for idx, row in enumerate(df['lemmas']):\n",
    "    # Notice that we put all tokens in the same list\n",
    "    tokens.extend(row.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bdbaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.text import Text\n",
    "\n",
    "aita_tokens = Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f267cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354d95ce",
   "metadata": {},
   "source": [
    "### Concordances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88557fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "aita_tokens.concordance('mistake', width=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59af8c48",
   "metadata": {},
   "source": [
    "### Collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b26500",
   "metadata": {},
   "outputs": [],
   "source": [
    "aita_tokens.collocation_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aba783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change input arguments\n",
    "aita_tokens.collocation_list(num=30, window_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b285e9",
   "metadata": {},
   "source": [
    "### Word Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f57e98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aita_tokens.dispersion_plot([\"Russian-Ukrainian War\", \"Question\", \"Discussion\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e66f28",
   "metadata": {},
   "source": [
    "### Similar Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781c9308",
   "metadata": {},
   "outputs": [],
   "source": [
    "aita_tokens.similar('partner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99957d53",
   "metadata": {},
   "source": [
    "### Common Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec66ddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "aita_tokens.common_contexts(['mom', 'dad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f23aed",
   "metadata": {},
   "source": [
    "## 2.4 Incorporating Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97ca9823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2008-04-08 05:21:54')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(1207632114, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b446d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idint</th>\n",
       "      <th>idstr</th>\n",
       "      <th>created</th>\n",
       "      <th>created_datetime</th>\n",
       "      <th>nsfw</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>distinguish</th>\n",
       "      <th>textlen</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>flair_text</th>\n",
       "      <th>flair_css_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>26781072</td>\n",
       "      <td>t3_fy0eo</td>\n",
       "      <td>1299351508</td>\n",
       "      <td>2011-03-05 18:58:28</td>\n",
       "      <td>0</td>\n",
       "      <td>margys</td>\n",
       "      <td>Мам, а когда я выросту, ты постареешь?...</td>\n",
       "      <td>Сегодня моя золотая птичка снова задалась вопр...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>26795140</td>\n",
       "      <td>t3_fyb9g</td>\n",
       "      <td>1299397232</td>\n",
       "      <td>2011-03-06 07:40:32</td>\n",
       "      <td>0</td>\n",
       "      <td>pozhaluista</td>\n",
       "      <td>Does the /r/ Ukraine have anyone here? Hello?</td>\n",
       "      <td>Seems quiet.</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>29482904</td>\n",
       "      <td>t3_hjx5k</td>\n",
       "      <td>1306343697</td>\n",
       "      <td>2011-05-25 17:14:57</td>\n",
       "      <td>0</td>\n",
       "      <td>visarun</td>\n",
       "      <td>Does immigration in Simferpol check whether th...</td>\n",
       "      <td>I have stayed 70 days and then 80 days out of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       idint     idstr     created    created_datetime  nsfw       author  \\\n",
       "35  26781072  t3_fy0eo  1299351508 2011-03-05 18:58:28     0       margys   \n",
       "36  26795140  t3_fyb9g  1299397232 2011-03-06 07:40:32     0  pozhaluista   \n",
       "50  29482904  t3_hjx5k  1306343697 2011-05-25 17:14:57     0      visarun   \n",
       "\n",
       "                                                title  \\\n",
       "35         Мам, а когда я выросту, ты постареешь?...    \n",
       "36      Does the /r/ Ukraine have anyone here? Hello?   \n",
       "50  Does immigration in Simferpol check whether th...   \n",
       "\n",
       "                                             selftext  score distinguish  \\\n",
       "35  Сегодня моя золотая птичка снова задалась вопр...      0         NaN   \n",
       "36                                      Seems quiet.      10         NaN   \n",
       "50  I have stayed 70 days and then 80 days out of ...      0         NaN   \n",
       "\n",
       "    textlen  num_comments flair_text flair_css_class  \n",
       "35      204             0        NaN             NaN  \n",
       "36       13            24        NaN             NaN  \n",
       "50      223             1        NaN             NaN  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new colum with date and time\n",
    "df.insert(loc=3, column='created_datetime', value=pd.to_datetime(df['created'], unit='s'))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8777dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011,\n",
      "            ...\n",
      "            2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022],\n",
      "           dtype='int64', name='created_datetime', length=16665)\n"
     ]
    }
   ],
   "source": [
    "#create new variables years\n",
    "years = pd.DatetimeIndex(df['created_datetime']).year\n",
    "print(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce3573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before 2013\n",
    "df_2013 = df.loc[(years <= 2013), :]\n",
    "len(df_2013)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b391db98",
   "metadata": {},
   "source": [
    "## Q. How to add another contraction after 2014?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3234899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after 2013 & before 2022\n",
    "df_b2022 = df.loc[(years <= 2022) & (years >=2013), :]\n",
    "len(df_b2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f180d231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after 2022\n",
    "df_a2022 = df.loc[(years >= 2022), :]\n",
    "len(df_a2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0692ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "sns.set(rc={'figure.figsize': (7, 5)})\n",
    "\n",
    "p = sns.histplot(\n",
    "    data=df_2021, \n",
    "    x=months_array,\n",
    "    hue=\"flair_css_class\",\n",
    "    multiple=\"stack\")\n",
    "\n",
    "plt.xticks(rotation=70)\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
