{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38102d51",
   "metadata": {},
   "source": [
    "# Data Science for Social Justice Workshop Group Project: Ukraine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1b7dea",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8addebb",
   "metadata": {},
   "source": [
    "### 1-1. Importing Data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4b6d530-f95c-40f1-8524-9c15d99a86cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\zhuli\\\\OneDrive\\\\Desktop\\\\data science + social justice\\\\Ukraine project'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd ##it will be different for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbafc694-fd59-40ee-af9c-f872850acc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7d422be",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('data') ##it will be different for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f92a399-4457-4235-a939-2981f2d77d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7167182c-c93f-4ce5-b175-f9f25142ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('submissions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90c57649-1694-453d-9f34-3512c7a49618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88764, 18)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3649eed0-ca67-4470-93a7-0d1bf100210f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['idint',\n",
       " 'idstr',\n",
       " 'created',\n",
       " 'self',\n",
       " 'nsfw',\n",
       " 'author',\n",
       " 'title',\n",
       " 'url',\n",
       " 'selftext',\n",
       " 'score',\n",
       " 'subreddit',\n",
       " 'distinguish',\n",
       " 'textlen',\n",
       " 'num_comments',\n",
       " 'flair_text',\n",
       " 'flair_css_class',\n",
       " 'augmented_at',\n",
       " 'augmented_count']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 18 variables\n",
    "list (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00e4b1c6-6236-4b12-8e6d-e6bdeecb9c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idint</th>\n",
       "      <th>idstr</th>\n",
       "      <th>created</th>\n",
       "      <th>self</th>\n",
       "      <th>nsfw</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>distinguish</th>\n",
       "      <th>textlen</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>flair_text</th>\n",
       "      <th>flair_css_class</th>\n",
       "      <th>augmented_at</th>\n",
       "      <th>augmented_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13054757</td>\n",
       "      <td>t3_7rt45</td>\n",
       "      <td>1232688225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nikitos2009</td>\n",
       "      <td>Лучший политический ресурс в Украине</td>\n",
       "      <td>http://pepper.at.ua/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13072291</td>\n",
       "      <td>t3_7s6n7</td>\n",
       "      <td>1232834472</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>OlehM</td>\n",
       "      <td>Dr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13093545</td>\n",
       "      <td>t3_7sn1l</td>\n",
       "      <td>1233019738</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nikitos2009</td>\n",
       "      <td>Основы гармонии украинства с московством</td>\n",
       "      <td>http://pepper.at.ua/publ/8-1-0-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13118896</td>\n",
       "      <td>t3_7t6ls</td>\n",
       "      <td>1233182615</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nikitos2009</td>\n",
       "      <td>Служба Бандеризации Украины выясняет кто убил ...</td>\n",
       "      <td>http://pepper.at.ua/publ/8-1-0-34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13238506</td>\n",
       "      <td>t3_7vqwa</td>\n",
       "      <td>1234081946</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ger4antche</td>\n",
       "      <td>amzek.blogspot.com</td>\n",
       "      <td>http://amzek.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      idint     idstr     created  self  nsfw       author  \\\n",
       "0  13054757  t3_7rt45  1232688225     0     0  nikitos2009   \n",
       "1  13072291  t3_7s6n7  1232834472     1     0        OlehM   \n",
       "2  13093545  t3_7sn1l  1233019738     0     0  nikitos2009   \n",
       "3  13118896  t3_7t6ls  1233182615     0     0  nikitos2009   \n",
       "4  13238506  t3_7vqwa  1234081946     0     0   ger4antche   \n",
       "\n",
       "                                               title  \\\n",
       "0               Лучший политический ресурс в Украине   \n",
       "1                                                 Dr   \n",
       "2           Основы гармонии украинства с московством   \n",
       "3  Служба Бандеризации Украины выясняет кто убил ...   \n",
       "4                                 amzek.blogspot.com   \n",
       "\n",
       "                                 url   selftext  score subreddit distinguish  \\\n",
       "0               http://pepper.at.ua/        NaN      0   ukraine         NaN   \n",
       "1                                NaN  [removed]      1   ukraine         NaN   \n",
       "2  http://pepper.at.ua/publ/8-1-0-30        NaN      1   ukraine         NaN   \n",
       "3  http://pepper.at.ua/publ/8-1-0-34        NaN      1   ukraine         NaN   \n",
       "4          http://amzek.blogspot.com        NaN      0   ukraine         NaN   \n",
       "\n",
       "   textlen  num_comments flair_text flair_css_class  augmented_at  \\\n",
       "0        0             0        NaN             NaN           NaN   \n",
       "1        9             0        NaN             NaN           NaN   \n",
       "2        0             0        NaN             NaN           NaN   \n",
       "3        0             0        NaN             NaN           NaN   \n",
       "4        0             1        NaN             NaN           NaN   \n",
       "\n",
       "   augmented_count  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a3a019",
   "metadata": {},
   "source": [
    "### 1-2. Dropping Columns and Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6020d763-032a-488b-93ee-2c9b767bdb5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idint</th>\n",
       "      <th>idstr</th>\n",
       "      <th>created</th>\n",
       "      <th>nsfw</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>distinguish</th>\n",
       "      <th>textlen</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>flair_text</th>\n",
       "      <th>flair_css_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13054757</td>\n",
       "      <td>t3_7rt45</td>\n",
       "      <td>1232688225</td>\n",
       "      <td>0</td>\n",
       "      <td>nikitos2009</td>\n",
       "      <td>Лучший политический ресурс в Украине</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13072291</td>\n",
       "      <td>t3_7s6n7</td>\n",
       "      <td>1232834472</td>\n",
       "      <td>0</td>\n",
       "      <td>OlehM</td>\n",
       "      <td>Dr</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13093545</td>\n",
       "      <td>t3_7sn1l</td>\n",
       "      <td>1233019738</td>\n",
       "      <td>0</td>\n",
       "      <td>nikitos2009</td>\n",
       "      <td>Основы гармонии украинства с московством</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13118896</td>\n",
       "      <td>t3_7t6ls</td>\n",
       "      <td>1233182615</td>\n",
       "      <td>0</td>\n",
       "      <td>nikitos2009</td>\n",
       "      <td>Служба Бандеризации Украины выясняет кто убил ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13238506</td>\n",
       "      <td>t3_7vqwa</td>\n",
       "      <td>1234081946</td>\n",
       "      <td>0</td>\n",
       "      <td>ger4antche</td>\n",
       "      <td>amzek.blogspot.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      idint     idstr     created  nsfw       author  \\\n",
       "0  13054757  t3_7rt45  1232688225     0  nikitos2009   \n",
       "1  13072291  t3_7s6n7  1232834472     0        OlehM   \n",
       "2  13093545  t3_7sn1l  1233019738     0  nikitos2009   \n",
       "3  13118896  t3_7t6ls  1233182615     0  nikitos2009   \n",
       "4  13238506  t3_7vqwa  1234081946     0   ger4antche   \n",
       "\n",
       "                                               title   selftext  score  \\\n",
       "0               Лучший политический ресурс в Украине        NaN      0   \n",
       "1                                                 Dr  [removed]      1   \n",
       "2           Основы гармонии украинства с московством        NaN      1   \n",
       "3  Служба Бандеризации Украины выясняет кто убил ...        NaN      1   \n",
       "4                                 amzek.blogspot.com        NaN      0   \n",
       "\n",
       "  distinguish  textlen  num_comments flair_text flair_css_class  \n",
       "0         NaN        0             0        NaN             NaN  \n",
       "1         NaN        9             0        NaN             NaN  \n",
       "2         NaN        0             0        NaN             NaN  \n",
       "3         NaN        0             0        NaN             NaN  \n",
       "4         NaN        0             1        NaN             NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##remove some columns that we are not going to use\n",
    "\n",
    "df = df.drop(['self', 'url', 'subreddit', 'augmented_at', 'augmented_count'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f58de402-9727-4941-8f00-769cdc4b8699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73414, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##get rid of posts that have been deleted/removed\n",
    "\n",
    "df = df.loc[~df['selftext'].isin(['[removed]', '[deleted]' ]),:]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce43e9a1-be78-413f-b7a0-05835e4bce69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16665, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## drop null values\n",
    "df = df.dropna(subset=['selftext'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b517ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idint</th>\n",
       "      <th>idstr</th>\n",
       "      <th>created</th>\n",
       "      <th>nsfw</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>distinguish</th>\n",
       "      <th>textlen</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>flair_text</th>\n",
       "      <th>flair_css_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>26781072</td>\n",
       "      <td>t3_fy0eo</td>\n",
       "      <td>1299351508</td>\n",
       "      <td>0</td>\n",
       "      <td>margys</td>\n",
       "      <td>Мам, а когда я выросту, ты постареешь?...</td>\n",
       "      <td>Сегодня моя золотая птичка снова задалась вопр...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>26795140</td>\n",
       "      <td>t3_fyb9g</td>\n",
       "      <td>1299397232</td>\n",
       "      <td>0</td>\n",
       "      <td>pozhaluista</td>\n",
       "      <td>Does the /r/ Ukraine have anyone here? Hello?</td>\n",
       "      <td>Seems quiet.</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>29482904</td>\n",
       "      <td>t3_hjx5k</td>\n",
       "      <td>1306343697</td>\n",
       "      <td>0</td>\n",
       "      <td>visarun</td>\n",
       "      <td>Does immigration in Simferpol check whether th...</td>\n",
       "      <td>I have stayed 70 days and then 80 days out of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>29608809</td>\n",
       "      <td>t3_hmmax</td>\n",
       "      <td>1306639850</td>\n",
       "      <td>0</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>Tickets to Ukraine from Seoul?</td>\n",
       "      <td>Hi everyone.  I'd like to visit Ukraine for th...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>281</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>33263382</td>\n",
       "      <td>t3_jsy6u</td>\n",
       "      <td>1314200067</td>\n",
       "      <td>0</td>\n",
       "      <td>lsakbaetle3r9</td>\n",
       "      <td>looking for someone</td>\n",
       "      <td>had a friend who moved to my town ~4-5 years a...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>386</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       idint     idstr     created  nsfw         author  \\\n",
       "35  26781072  t3_fy0eo  1299351508     0         margys   \n",
       "36  26795140  t3_fyb9g  1299397232     0    pozhaluista   \n",
       "50  29482904  t3_hjx5k  1306343697     0        visarun   \n",
       "51  29608809  t3_hmmax  1306639850     0      [deleted]   \n",
       "62  33263382  t3_jsy6u  1314200067     0  lsakbaetle3r9   \n",
       "\n",
       "                                                title  \\\n",
       "35         Мам, а когда я выросту, ты постареешь?...    \n",
       "36      Does the /r/ Ukraine have anyone here? Hello?   \n",
       "50  Does immigration in Simferpol check whether th...   \n",
       "51                     Tickets to Ukraine from Seoul?   \n",
       "62                                looking for someone   \n",
       "\n",
       "                                             selftext  score distinguish  \\\n",
       "35  Сегодня моя золотая птичка снова задалась вопр...      0         NaN   \n",
       "36                                      Seems quiet.      10         NaN   \n",
       "50  I have stayed 70 days and then 80 days out of ...      0         NaN   \n",
       "51  Hi everyone.  I'd like to visit Ukraine for th...      2         NaN   \n",
       "62  had a friend who moved to my town ~4-5 years a...      3         NaN   \n",
       "\n",
       "    textlen  num_comments flair_text flair_css_class  \n",
       "35      204             0        NaN             NaN  \n",
       "36       13            24        NaN             NaN  \n",
       "50      223             1        NaN             NaN  \n",
       "51      281             0        NaN             NaN  \n",
       "62      386             1        NaN             NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f126981c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (1.0.9)\n",
      "Requirement already satisfied: six in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from langdetect) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "##remove the rows with non-enlish text\n",
    "!pip install langdetect\n",
    "from langdetect import detect\n",
    "df['detect'] = detect(str(df['selftext']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "885b7ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idint</th>\n",
       "      <th>idstr</th>\n",
       "      <th>created</th>\n",
       "      <th>nsfw</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>distinguish</th>\n",
       "      <th>textlen</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>flair_text</th>\n",
       "      <th>flair_css_class</th>\n",
       "      <th>detect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>26781072</td>\n",
       "      <td>t3_fy0eo</td>\n",
       "      <td>1299351508</td>\n",
       "      <td>0</td>\n",
       "      <td>margys</td>\n",
       "      <td>Мам, а когда я выросту, ты постареешь?...</td>\n",
       "      <td>Сегодня моя золотая птичка снова задалась вопр...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>26795140</td>\n",
       "      <td>t3_fyb9g</td>\n",
       "      <td>1299397232</td>\n",
       "      <td>0</td>\n",
       "      <td>pozhaluista</td>\n",
       "      <td>Does the /r/ Ukraine have anyone here? Hello?</td>\n",
       "      <td>Seems quiet.</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>29482904</td>\n",
       "      <td>t3_hjx5k</td>\n",
       "      <td>1306343697</td>\n",
       "      <td>0</td>\n",
       "      <td>visarun</td>\n",
       "      <td>Does immigration in Simferpol check whether th...</td>\n",
       "      <td>I have stayed 70 days and then 80 days out of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>29608809</td>\n",
       "      <td>t3_hmmax</td>\n",
       "      <td>1306639850</td>\n",
       "      <td>0</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>Tickets to Ukraine from Seoul?</td>\n",
       "      <td>Hi everyone.  I'd like to visit Ukraine for th...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>281</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>33263382</td>\n",
       "      <td>t3_jsy6u</td>\n",
       "      <td>1314200067</td>\n",
       "      <td>0</td>\n",
       "      <td>lsakbaetle3r9</td>\n",
       "      <td>looking for someone</td>\n",
       "      <td>had a friend who moved to my town ~4-5 years a...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>386</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       idint     idstr     created  nsfw         author  \\\n",
       "35  26781072  t3_fy0eo  1299351508     0         margys   \n",
       "36  26795140  t3_fyb9g  1299397232     0    pozhaluista   \n",
       "50  29482904  t3_hjx5k  1306343697     0        visarun   \n",
       "51  29608809  t3_hmmax  1306639850     0      [deleted]   \n",
       "62  33263382  t3_jsy6u  1314200067     0  lsakbaetle3r9   \n",
       "\n",
       "                                                title  \\\n",
       "35         Мам, а когда я выросту, ты постареешь?...    \n",
       "36      Does the /r/ Ukraine have anyone here? Hello?   \n",
       "50  Does immigration in Simferpol check whether th...   \n",
       "51                     Tickets to Ukraine from Seoul?   \n",
       "62                                looking for someone   \n",
       "\n",
       "                                             selftext  score distinguish  \\\n",
       "35  Сегодня моя золотая птичка снова задалась вопр...      0         NaN   \n",
       "36                                      Seems quiet.      10         NaN   \n",
       "50  I have stayed 70 days and then 80 days out of ...      0         NaN   \n",
       "51  Hi everyone.  I'd like to visit Ukraine for th...      2         NaN   \n",
       "62  had a friend who moved to my town ~4-5 years a...      3         NaN   \n",
       "\n",
       "    textlen  num_comments flair_text flair_css_class detect  \n",
       "35      204             0        NaN             NaN     en  \n",
       "36       13            24        NaN             NaN     en  \n",
       "50      223             1        NaN             NaN     en  \n",
       "51      281             0        NaN             NaN     en  \n",
       "62      386             1        NaN             NaN     en  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35800ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['detect'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82973954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16665, 14)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b174a7b4",
   "metadata": {},
   "source": [
    "### MJ: Q. The command above did not give correct results e.g., the first row is in Russian, but the detect column says it is English. It is why the dataframe still have 16665 rows. So I tried the command below, but encountered error. I just moved on to next steps. We can apply the language detection codes later and run the notebook again:)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d96d51e",
   "metadata": {},
   "outputs": [
    {
     "ename": "LangDetectException",
     "evalue": "No features in text.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLangDetectException\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdetect2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mselftext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetect\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langdetect\\detector_factory.py:130\u001b[0m, in \u001b[0;36mdetect\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    128\u001b[0m detector \u001b[38;5;241m=\u001b[39m _factory\u001b[38;5;241m.\u001b[39mcreate()\n\u001b[0;32m    129\u001b[0m detector\u001b[38;5;241m.\u001b[39mappend(text)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langdetect\\detector.py:136\u001b[0m, in \u001b[0;36mDetector.detect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;124;03m'''Detect language of the target text and return the language name\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;124;03m    which has the highest probability.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m--> 136\u001b[0m     probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m probabilities:\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m probabilities[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlang\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langdetect\\detector.py:143\u001b[0m, in \u001b[0;36mDetector.get_probabilities\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_probabilities\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlangprob \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_detect_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sort_probability(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlangprob)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langdetect\\detector.py:150\u001b[0m, in \u001b[0;36mDetector._detect_block\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    148\u001b[0m ngrams \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_ngrams()\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ngrams:\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LangDetectException(ErrorCode\u001b[38;5;241m.\u001b[39mCantDetectError, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo features in text.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlangprob \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlanglist)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)\n",
      "\u001b[1;31mLangDetectException\u001b[0m: No features in text."
     ]
    }
   ],
   "source": [
    "df['detect2'] = df['selftext'].apply(detect) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7482e5",
   "metadata": {},
   "source": [
    "### 1-3. Cleaning Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48f15a8e-4dc2-4c70-8aeb-d6156d5a40c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (3.4.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy) (61.2.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy) (1.0.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy) (2.4.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy) (1.9.1)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy) (8.1.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy) (4.1.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Collecting en-core-web-sm==3.4.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.4.0) (3.4.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (21.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.11.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.7)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.9.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.9.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.64.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.21.5)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (61.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.27.1)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.7.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "443f2abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spaCy\n",
    "import spacy\n",
    "# Load the English preprocessing pipeline\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc918310-c081-48cf-9474-d1b0a95d0cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сегодня моя золотая птичка снова задалась вопросом... \"Мам, а когда я выросту, ты постареешь?... а потом умрешь? ... и папа?... Мамочка, я не хочу взрослеть, можно я навсегда останусь такой маленькой?...\"\n"
     ]
    }
   ],
   "source": [
    "# Test: Parse the first reddit post in the dataset\n",
    "parsed_post = nlp(df.selftext.iloc[0])\n",
    "print(parsed_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70d6cf85-4c62-4f90-8adc-ce3b3c4ce500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1\n",
      "Сегодня моя золотая птичка снова задалась вопросом...\n",
      "\n",
      "Sentence 2\n",
      "\"Мам, а когда я выросту, ты постареешь?...\n",
      "\n",
      "Sentence 3\n",
      "а потом умрешь? ...\n",
      "\n",
      "Sentence 4\n",
      "и папа?...\n",
      "\n",
      "Sentence 5\n",
      "Мамочка, я не хочу взрослеть, можно я навсегда останусь такой маленькой?...\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print each sentence in the parsed post\n",
    "for idx, sentence in enumerate(parsed_post.sents):  \n",
    "    ##In python, .sents is used for \"sentence segmentation\" which is present inside spacy. \n",
    "    print(f'Sentence {idx + 1}')\n",
    "    print(sentence)\n",
    "    print('') #space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "271e0e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_text</th>\n",
       "      <th>part_of_speech</th>\n",
       "      <th>token_lemma</th>\n",
       "      <th>token_stop</th>\n",
       "      <th>token_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Сегодня</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>сегодня</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>моя</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>моя</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>золотая</td>\n",
       "      <td>VERB</td>\n",
       "      <td>золотая</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>птичка</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>птичка</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>снова</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>снова</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>задалась</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>задалась</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>вопросом</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>вопросом</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>...</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>\"</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Мам</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Мам</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>а</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>а</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>когда</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>когда</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>я</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>я</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>выросту</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>выросту</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token_text part_of_speech token_lemma  token_stop  token_punct\n",
       "0     Сегодня            ADJ     сегодня       False        False\n",
       "1         моя           NOUN         моя       False        False\n",
       "2     золотая           VERB     золотая       False        False\n",
       "3      птичка          PROPN      птичка       False        False\n",
       "4       снова          PROPN       снова       False        False\n",
       "5    задалась          PROPN    задалась       False        False\n",
       "6    вопросом          PROPN    вопросом       False        False\n",
       "7         ...          PUNCT         ...       False         True\n",
       "8           \"          PUNCT           \"       False         True\n",
       "9         Мам          PROPN         Мам       False        False\n",
       "10          ,          PUNCT           ,       False         True\n",
       "11          а          PROPN           а       False        False\n",
       "12      когда          PROPN       когда       False        False\n",
       "13          я          PROPN           я       False        False\n",
       "14    выросту          PROPN     выросту       False        False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the first 15 items for the following properties of the parsed post\n",
    "\n",
    "# The token text \n",
    "token_text = [token.orth_ for token in parsed_post][:15]   \n",
    "# Part of speech \n",
    "token_pos = [token.pos_ for token in parsed_post][:15]   \n",
    "# Lemma (or 'dictionary form')\n",
    "token_lemma = [token.lemma_ for token in parsed_post][:15]\n",
    "# Stop word? t/f\n",
    "token_stop = [token.is_stop for token in parsed_post][:15]\n",
    "# Puncutation? t/f\n",
    "token_punct = [token.is_punct for token in parsed_post][:15]\n",
    "\n",
    "# Make a dataframe with these items\n",
    "pd.DataFrame(zip(token_text, token_pos, token_lemma, token_stop, token_punct),\n",
    "             columns=['token_text', 'part_of_speech', 'token_lemma', 'token_stop', 'token_punct'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e56f9",
   "metadata": {},
   "source": [
    "### 1-4. Preprocessing all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "629cb596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0d11084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(token):\n",
    "    \"\"\"Helper function that specifies whether a token is:\n",
    "        - punctuation\n",
    "        - space\n",
    "        - digit\n",
    "    \"\"\"\n",
    "    return token.is_punct or token.is_space or token.is_digit\n",
    "\n",
    "def line_read(df, text_col='selftext'):\n",
    "    \"\"\"Generator function to read in text from df and get rid of line breaks.\"\"\"    \n",
    "    for text in df[text_col]:\n",
    "        yield text.replace('\\n', '')\n",
    "\n",
    "def preprocess(df, text_col='selftext', allowed_postags=['NOUN', 'ADJ']):\n",
    "    \"\"\"Preprocessing function to apply to a dataframe.\"\"\"\n",
    "    for parsed in nlp.pipe(line_read(df, text_col), batch_size=1000, disable=[\"tok2vec\", \"ner\"]):\n",
    "        # Gather lowercased, lemmatized tokens\n",
    "        tokens = [token.lemma_.lower() if token.lemma_ != '-PRON-'\n",
    "                  else token.lower_ \n",
    "                  for token in parsed if not clean(token)]\n",
    "        # Remove specific lemmatizations, and words that are not nouns or adjectives\n",
    "        tokens = [lemma\n",
    "                  for lemma in tokens\n",
    "                  if not lemma in [\"'s\",  \"’s\", \"’\"] and not lemma in allowed_postags]\n",
    "        # Remove stop words\n",
    "        tokens = [token for token in tokens if token not in spacy.lang.en.stop_words.STOP_WORDS]\n",
    "        yield tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2d05657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This may take a while\n",
    "lemmas = [line for line in preprocess(df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0107553-fa22-47b5-9bfa-7afe58c1e4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stayed',\n",
       " 'days',\n",
       " 'days',\n",
       " 'days',\n",
       " 'know',\n",
       " 'borispol',\n",
       " 'pretty',\n",
       " 'strict',\n",
       " 'checking',\n",
       " 'ones',\n",
       " 'passport',\n",
       " 'simferopol',\n",
       " 'airport',\n",
       " 'strict',\n",
       " 'better',\n",
       " 'use',\n",
       " 'land',\n",
       " 'border',\n",
       " 'crossing',\n",
       " 'lviv',\n",
       " 'poland']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18403226-cabe-41ae-9499-427a54122846",
   "metadata": {},
   "source": [
    "### 1-5.Phrase Modeling with `gensim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd61684f-3ef7-47d8-a7ab-0fc1e61bea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "# Create bigram and trigram models\n",
    "bigram = Phrases(lemmas, min_count=10, threshold=100)\n",
    "trigram = Phrases(bigram[lemmas], min_count=10, threshold=50)  \n",
    "bigram_phraser = Phraser(bigram)\n",
    "trigram_phraser = Phraser(trigram)\n",
    "\n",
    "# Form trigrams\n",
    "trigrams = [trigram_phraser[bigram_phraser[doc]] for doc in lemmas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48ac415e-aedf-406b-ab33-f133bcc9cc1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'сегодня моя золотая птичка снова задалась вопросом мам а когда я выросту ты постареешь а потом умрешь и папа мамочка я_не хочу взрослеть можно я навсегда останусь такой маленькой'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join each into a string\n",
    "trigrams_joined = [' '.join(trigram) for trigram in trigrams]\n",
    "trigrams_joined[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46509ba8-2269-440d-9ab3-e33e90691a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "542"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can use .keys() to identify the bigrams in the dataset. How many bigrams were identified by the parser?\n",
    "len(bigram_phraser.phrasegrams.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f754728-8abe-4f5c-a3bf-a3e6ff051dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['border_crossing',\n",
       " 'shed_light',\n",
       " 'years_ago',\n",
       " 'hey_guys',\n",
       " 'thanks_advance',\n",
       " 'eastern_europe',\n",
       " 'eastern_european',\n",
       " 'english_speakers',\n",
       " 'cross_border',\n",
       " 'story_short']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at biagrams\n",
    "list(bigram_phraser.phrasegrams.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e53a815d-5212-4317-ba74-4a4b7f596c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['long_story_short',\n",
       " 'ministry_foreign_affairs',\n",
       " 'euromaidan_pr_twitter](http://goo.gl',\n",
       " 'euromaidan_pr_facebook](http://goo.gl',\n",
       " 'ukrainian_brothers_sisters',\n",
       " 'minister_foreign_affairs',\n",
       " 'having_trouble_finding',\n",
       " 'un_security_council',\n",
       " 'worst_case_scenario',\n",
       " 'united_states_america',\n",
       " 'native_english_speaker',\n",
       " '=_webp&s_=',\n",
       " 'black_sea_fleet',\n",
       " 'view_poll](https://www.reddit.com_poll',\n",
       " 'якщо_у_вас',\n",
       " 'sovereignty_territorial_integrity',\n",
       " '=_share&utm_medium',\n",
       " 'ukraine_🇺_🇦',\n",
       " 'anti_tank_weapons',\n",
       " 'donetsk_luhansk_regions',\n",
       " 'committing_war_crimes',\n",
       " 'news_spread_likely',\n",
       " 'russia_backed_trolls',\n",
       " 'reception_points_ready',\n",
       " \"right_edit_don't\",\n",
       " 'need_visa_pass',\n",
       " 'need_passport_visas',\n",
       " \"suspended_don't_need\",\n",
       " 'need_visa:•_\\u2060in',\n",
       " 'ukrainian_https://www.gov.pl/web/udsc/ukraina---ua_\\u2060in',\n",
       " 'copy_paste_encourage',\n",
       " 'https://www.gov.pl/web/udsc/ukraina---ua_\\u2060in_english',\n",
       " 'використовував_google_translate',\n",
       " 'bic_nbua_ua',\n",
       " 'address_instytutska_st',\n",
       " 'initial_evaluation_management',\n",
       " 'air_raid_sirens',\n",
       " 'urban_warfare_tips',\n",
       " 'air_raid_siren',\n",
       " 'nuclear_power_plant',\n",
       " 'площадь_ленина_🔻']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at trigrams\n",
    "[trigram for trigram in list(trigram_phraser.phrasegrams.keys()) if trigram.count('_') == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c691a8ee-1857-4ac8-9c1f-187cb118fb7a",
   "metadata": {},
   "source": [
    "### 1-6. Save the file after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf56a767-36f8-4a1e-b2f9-c2ee9bf4a19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserting next to selftext column\n",
    "df.insert(loc=7, column='lemmas', value=trigrams_joined)\n",
    "# Removing empty rows in lemmas\n",
    "df = df[~df['lemmas'].isin([''])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5156f53e-5072-4eb4-b094-48d8f92a12ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idint</th>\n",
       "      <th>idstr</th>\n",
       "      <th>created</th>\n",
       "      <th>nsfw</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>score</th>\n",
       "      <th>distinguish</th>\n",
       "      <th>textlen</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>flair_text</th>\n",
       "      <th>flair_css_class</th>\n",
       "      <th>detect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>26781072</td>\n",
       "      <td>t3_fy0eo</td>\n",
       "      <td>1299351508</td>\n",
       "      <td>0</td>\n",
       "      <td>margys</td>\n",
       "      <td>Мам, а когда я выросту, ты постареешь?...</td>\n",
       "      <td>Сегодня моя золотая птичка снова задалась вопр...</td>\n",
       "      <td>сегодня моя золотая птичка снова задалась вопр...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>26795140</td>\n",
       "      <td>t3_fyb9g</td>\n",
       "      <td>1299397232</td>\n",
       "      <td>0</td>\n",
       "      <td>pozhaluista</td>\n",
       "      <td>Does the /r/ Ukraine have anyone here? Hello?</td>\n",
       "      <td>Seems quiet.</td>\n",
       "      <td>quiet</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>29482904</td>\n",
       "      <td>t3_hjx5k</td>\n",
       "      <td>1306343697</td>\n",
       "      <td>0</td>\n",
       "      <td>visarun</td>\n",
       "      <td>Does immigration in Simferpol check whether th...</td>\n",
       "      <td>I have stayed 70 days and then 80 days out of ...</td>\n",
       "      <td>stayed days days days know borispol pretty str...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>29608809</td>\n",
       "      <td>t3_hmmax</td>\n",
       "      <td>1306639850</td>\n",
       "      <td>0</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>Tickets to Ukraine from Seoul?</td>\n",
       "      <td>Hi everyone.  I'd like to visit Ukraine for th...</td>\n",
       "      <td>hi like visit ukraine time looking cheap ticke...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>281</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>33263382</td>\n",
       "      <td>t3_jsy6u</td>\n",
       "      <td>1314200067</td>\n",
       "      <td>0</td>\n",
       "      <td>lsakbaetle3r9</td>\n",
       "      <td>looking for someone</td>\n",
       "      <td>had a friend who moved to my town ~4-5 years a...</td>\n",
       "      <td>friend moved town ~4 years ago.he myspace acce...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>386</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       idint     idstr     created  nsfw         author  \\\n",
       "35  26781072  t3_fy0eo  1299351508     0         margys   \n",
       "36  26795140  t3_fyb9g  1299397232     0    pozhaluista   \n",
       "50  29482904  t3_hjx5k  1306343697     0        visarun   \n",
       "51  29608809  t3_hmmax  1306639850     0      [deleted]   \n",
       "62  33263382  t3_jsy6u  1314200067     0  lsakbaetle3r9   \n",
       "\n",
       "                                                title  \\\n",
       "35         Мам, а когда я выросту, ты постареешь?...    \n",
       "36      Does the /r/ Ukraine have anyone here? Hello?   \n",
       "50  Does immigration in Simferpol check whether th...   \n",
       "51                     Tickets to Ukraine from Seoul?   \n",
       "62                                looking for someone   \n",
       "\n",
       "                                             selftext  \\\n",
       "35  Сегодня моя золотая птичка снова задалась вопр...   \n",
       "36                                      Seems quiet.    \n",
       "50  I have stayed 70 days and then 80 days out of ...   \n",
       "51  Hi everyone.  I'd like to visit Ukraine for th...   \n",
       "62  had a friend who moved to my town ~4-5 years a...   \n",
       "\n",
       "                                               lemmas  score distinguish  \\\n",
       "35  сегодня моя золотая птичка снова задалась вопр...      0         NaN   \n",
       "36                                              quiet     10         NaN   \n",
       "50  stayed days days days know borispol pretty str...      0         NaN   \n",
       "51  hi like visit ukraine time looking cheap ticke...      2         NaN   \n",
       "62  friend moved town ~4 years ago.he myspace acce...      3         NaN   \n",
       "\n",
       "    textlen  num_comments flair_text flair_css_class detect  \n",
       "35      204             0        NaN             NaN     en  \n",
       "36       13            24        NaN             NaN     en  \n",
       "50      223             1        NaN             NaN     en  \n",
       "51      281             0        NaN             NaN     en  \n",
       "62      386             1        NaN             NaN     en  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40128c0f-1221-47bc-84e1-ff9bce565b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to new csv\n",
    "df.to_csv('ukraine_lemmas.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1471acc6-8ecc-443a-8fbe-48f4cf4c7c89",
   "metadata": {},
   "source": [
    "### For the next steps, make sure to use the file: 'ukraine_lemmas.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360dd5f6-d48e-4417-8556-8d574ff1e8e7",
   "metadata": {},
   "source": [
    "## 2. Exploring Texts \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdb3118-1c93-42f1-baee-3257d5815084",
   "metadata": {},
   "source": [
    "### 2-1. Diving Deeper into `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff5e7b30-1e87-4172-b670-ccb5c54f4913",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ukraine_lemmas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "813e04df-397b-4dd3-ab12-b8ad86fcc7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idint</th>\n",
       "      <th>idstr</th>\n",
       "      <th>created</th>\n",
       "      <th>nsfw</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>score</th>\n",
       "      <th>distinguish</th>\n",
       "      <th>textlen</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>flair_text</th>\n",
       "      <th>flair_css_class</th>\n",
       "      <th>detect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26781072</td>\n",
       "      <td>t3_fy0eo</td>\n",
       "      <td>1299351508</td>\n",
       "      <td>0</td>\n",
       "      <td>margys</td>\n",
       "      <td>Мам, а когда я выросту, ты постареешь?...</td>\n",
       "      <td>Сегодня моя золотая птичка снова задалась вопр...</td>\n",
       "      <td>сегодня моя золотая птичка снова задалась вопр...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26795140</td>\n",
       "      <td>t3_fyb9g</td>\n",
       "      <td>1299397232</td>\n",
       "      <td>0</td>\n",
       "      <td>pozhaluista</td>\n",
       "      <td>Does the /r/ Ukraine have anyone here? Hello?</td>\n",
       "      <td>Seems quiet.</td>\n",
       "      <td>quiet</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29482904</td>\n",
       "      <td>t3_hjx5k</td>\n",
       "      <td>1306343697</td>\n",
       "      <td>0</td>\n",
       "      <td>visarun</td>\n",
       "      <td>Does immigration in Simferpol check whether th...</td>\n",
       "      <td>I have stayed 70 days and then 80 days out of ...</td>\n",
       "      <td>stayed days days days know borispol pretty str...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      idint     idstr     created  nsfw       author  \\\n",
       "0  26781072  t3_fy0eo  1299351508     0       margys   \n",
       "1  26795140  t3_fyb9g  1299397232     0  pozhaluista   \n",
       "2  29482904  t3_hjx5k  1306343697     0      visarun   \n",
       "\n",
       "                                               title  \\\n",
       "0         Мам, а когда я выросту, ты постареешь?...    \n",
       "1      Does the /r/ Ukraine have anyone here? Hello?   \n",
       "2  Does immigration in Simferpol check whether th...   \n",
       "\n",
       "                                            selftext  \\\n",
       "0  Сегодня моя золотая птичка снова задалась вопр...   \n",
       "1                                      Seems quiet.    \n",
       "2  I have stayed 70 days and then 80 days out of ...   \n",
       "\n",
       "                                              lemmas  score distinguish  \\\n",
       "0  сегодня моя золотая птичка снова задалась вопр...      0         NaN   \n",
       "1                                              quiet     10         NaN   \n",
       "2  stayed days days days know borispol pretty str...      0         NaN   \n",
       "\n",
       "   textlen  num_comments flair_text flair_css_class detect  \n",
       "0      204             0        NaN             NaN     en  \n",
       "1       13            24        NaN             NaN     en  \n",
       "2      223             1        NaN             NaN     en  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63ab0901-2c06-4d78-bfeb-95972d36a985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idint</th>\n",
       "      <th>idstr</th>\n",
       "      <th>created</th>\n",
       "      <th>nsfw</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>score</th>\n",
       "      <th>distinguish</th>\n",
       "      <th>textlen</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>flair_text</th>\n",
       "      <th>flair_css_class</th>\n",
       "      <th>detect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11130</th>\n",
       "      <td>1757241133</td>\n",
       "      <td>t3_t27rxp</td>\n",
       "      <td>1645911562</td>\n",
       "      <td>0</td>\n",
       "      <td>Ghost1069</td>\n",
       "      <td>Officials in Ukraine are doing their best to s...</td>\n",
       "      <td>-- EDIT FOR SUMY --- AIR RAID ON SUMY --- \\n\\n...</td>\n",
       "      <td>edit sumy air_raid sumy shelter sumy shelter s...</td>\n",
       "      <td>164624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8927</th>\n",
       "      <td>1753516706</td>\n",
       "      <td>t3_szzy5e</td>\n",
       "      <td>1645671618</td>\n",
       "      <td>0</td>\n",
       "      <td>soff_mm</td>\n",
       "      <td>It is an honor to be a Ukrainian at this hour.</td>\n",
       "      <td>We're staying strong. Support the Armed Forces...</td>\n",
       "      <td>staying strong support armed_forces ukraine</td>\n",
       "      <td>48955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "      <td>2154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15629</th>\n",
       "      <td>1766534572</td>\n",
       "      <td>t3_t7qyss</td>\n",
       "      <td>1646540863</td>\n",
       "      <td>0</td>\n",
       "      <td>sharag123</td>\n",
       "      <td>It is almost 7am and the Sun has Risen on the ...</td>\n",
       "      <td>&amp;#x200B;</td>\n",
       "      <td>x200b</td>\n",
       "      <td>33895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>531</td>\n",
       "      <td>WAR</td>\n",
       "      <td>war</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            idint      idstr     created  nsfw     author  \\\n",
       "11130  1757241133  t3_t27rxp  1645911562     0  Ghost1069   \n",
       "8927   1753516706  t3_szzy5e  1645671618     0    soff_mm   \n",
       "15629  1766534572  t3_t7qyss  1646540863     0  sharag123   \n",
       "\n",
       "                                                   title  \\\n",
       "11130  Officials in Ukraine are doing their best to s...   \n",
       "8927      It is an honor to be a Ukrainian at this hour.   \n",
       "15629  It is almost 7am and the Sun has Risen on the ...   \n",
       "\n",
       "                                                selftext  \\\n",
       "11130  -- EDIT FOR SUMY --- AIR RAID ON SUMY --- \\n\\n...   \n",
       "8927   We're staying strong. Support the Armed Forces...   \n",
       "15629                                           &#x200B;   \n",
       "\n",
       "                                                  lemmas   score distinguish  \\\n",
       "11130  edit sumy air_raid sumy shelter sumy shelter s...  164624         NaN   \n",
       "8927         staying strong support armed_forces ukraine   48955         NaN   \n",
       "15629                                              x200b   33895         NaN   \n",
       "\n",
       "       textlen  num_comments flair_text flair_css_class detect  \n",
       "11130        0          3099        NaN             NaN     en  \n",
       "8927        66          2154        NaN             NaN     en  \n",
       "15629       39           531        WAR             war     en  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort dataframe by highest scores\n",
    "df.sort_values(by=['score'], ascending=False)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc65ef9e-5bce-4887-a0ba-b61748939bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows with a score higher than 500\n",
    "df_top = df.loc[df['score'] >= 500, :]\n",
    "len(df_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14cd4387-8692-43e1-acdd-625c2110f099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Russian-Ukrainian War       1989\n",
       "Question                    1380\n",
       "Discussion                  1227\n",
       "News                         393\n",
       "Request                      262\n",
       "WAR                          205\n",
       "Travel                       181\n",
       "Military                     119\n",
       "History                       70\n",
       "Media                         70\n",
       "Social Media                  69\n",
       "Humor                         63\n",
       "Russo-Ukrainian War           59\n",
       "Moving to Ukraine             43\n",
       "Music                         38\n",
       "WAR CRIME                     30\n",
       "Shitpost                      30\n",
       "War Crimes                    24\n",
       "Cuisine                       16\n",
       "Russian Protest               15\n",
       "Important                     14\n",
       "Video                         12\n",
       "Social media                  10\n",
       "Photo                         10\n",
       "Government (Unconfirmed)       7\n",
       "Tweet                          4\n",
       "Unconfirmed                    3\n",
       "Need help                      3\n",
       "WAR | Misleading               1\n",
       "Goverment (Unconfirmed)        1\n",
       "RATE MY BORSHCH!               1\n",
       ":FlagUA: Government            1\n",
       "Misleading                     1\n",
       "ASTARTES                       1\n",
       "Help                           1\n",
       "Name: flair_text, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique value counts for a column\n",
    "df.flair_text.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e44a11-cf7d-4d93-bdb9-e747419ceb34",
   "metadata": {},
   "source": [
    "### 2-2 Type-token ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89c7d00a-28ea-452e-a9cb-61386986d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the TTR\n",
    "\n",
    "def type_token_ratio(tokens):\n",
    "    \"\"\"Calculates type-token ratio on tokens.\"\"\"\n",
    "    numTokens = len(tokens)\n",
    "    numTypes = len(set(tokens))\n",
    "    return numTypes / numTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3265b219-6865-444e-9088-649adee463e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      " сегодня моя золотая птичка снова задалась вопросом мам а когда я выросту ты постареешь а потом умрешь и папа мамочка я_не хочу взрослеть можно я навсегда останусь такой маленькой\n",
      "TTR: 0.9310344827586207 \n",
      "\n",
      "Text:\n",
      " quiet\n",
      "TTR: 1.0 \n",
      "\n",
      "Text:\n",
      " stayed days days days know borispol pretty strict checking ones passport simferopol airport strict better use land border_crossing lviv poland\n",
      "TTR: 0.85 \n",
      "\n",
      "Text:\n",
      " hi like visit ukraine time looking cheap tickets seoul->kiev->seoul june june flexible seoul june 25/26).could suggest cheapest way fly?thanks advance\n",
      "TTR: 0.9 \n",
      "\n",
      "Text:\n",
      " friend moved town ~4 years ago.he myspace accessed long time.he mail.ru email played drugswars.ru game lolhes kiev wondering knows uk social networking site maybe me?pm u wanna help nt wanna blast\n",
      "TTR: 0.967741935483871 \n",
      "\n",
      "Text:\n",
      " hey /r ukraine trying connect roots trying find meaning sticks usa hlusko found lemko origin people caspian mountains language supposed like ukrainian shed_light me?tldr hlusko mean language\n",
      "TTR: 0.8888888888888888 \n",
      "\n",
      "Text:\n",
      " redditors sure day probably monday tuesday 27.09\n",
      "TTR: 1.0 \n",
      "\n",
      "Text:\n",
      " new reddit\n",
      "TTR: 1.0 \n",
      "\n",
      "Text:\n",
      " friends working school project nuclear disaster chernobyl years_ago booked tickets kiev arranged tour area contamination pripjat plan visit museum goal trip gather information possible consequences disaster native ukrainians redditors living think maybe general tips visiting kiev non ukrainian russian speaker fluent_english know bit german\n",
      "TTR: 0.9545454545454546 \n",
      "\n",
      "Text:\n",
      " group friends planning going kiev european cup summer want rent house guys know good websites purpose find sketchy looking ones\n",
      "TTR: 1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#loop over the first 10 lemmatized submissions into dataframe\n",
    "\n",
    "for text in df['lemmas'][:10]:\n",
    "    tokens = text.split()\n",
    "    print('Text:\\n', text)\n",
    "    print('TTR:', type_token_ratio(tokens), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c67410-192b-44ee-a144-8c512acfafc2",
   "metadata": {},
   "source": [
    "### 2-3 Processing and Analyzing Language with `Text()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3b7cda1-f538-4adb-8e77-e04b71ffce75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: click in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\zhuli\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "# Run if you do not have nltk installed\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9fbaea6-9b0b-4c28-81d8-a83fe359bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for idx, row in enumerate(df['lemmas']):\n",
    "    # Notice that we put all tokens in the same list\n",
    "    tokens.extend(row.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fdefa0af-c8ad-4557-9799-e58769379eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zhuli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.text import Text\n",
    "\n",
    "##aita_tokens = Text(tokens)\n",
    "ukraine_tokens = Text(tokens) ##MJ: I changed the name to make it corresponding to our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6aa009-f419-4610-9d48-e866a33b02ac",
   "metadata": {},
   "source": [
    "### Concordances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7c92ad05-b5a6-46bc-991b-a136668962b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('removed][view_poll](https://www.reddit.com', 'poll'),\n",
       " ('let', 'know'),\n",
       " ('=_png&auto', '=_webp&s_='),\n",
       " ('aid_polish_government_launched', 'dedicated_site'),\n",
       " ('ready_arrival_reception_points', 'ready_border'),\n",
       " ('shelter_food_medical_legal', 'aid_polish_government_launched'),\n",
       " ('seek_asylum_polish_border', 'ready_arrival_reception_points'),\n",
       " ('russia_backed_trolls', 'polish_border_closed_lie'),\n",
       " ('polish_border_closed_lie', 'seek_asylum_polish_border'),\n",
       " ('share_information', 'know_seeking'),\n",
       " ('=_pjpg&auto', '=_webp&s_='),\n",
       " ('need_passport_visas', \"suspended_don't_need\"),\n",
       " ('russian', 'soldiers'),\n",
       " ('dedicated_site', 'help_ua.gov.plplease'),\n",
       " ('news_spread_likely', 'russia_backed_trolls'),\n",
       " ('help_ua.gov.plplease', 'share_information'),\n",
       " ('polish_border', 'need_passport_visas'),\n",
       " ('feel', 'like'),\n",
       " ('dear_ukrainians!i_heard_social', 'media_fake'),\n",
       " ('media_fake', 'news_spread_likely')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ukraine_tokens.collocation_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2109ee96-7b93-4635-933f-683852a5d1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('removed][view_poll](https://www.reddit.com', 'poll'),\n",
       " ('let', 'know'),\n",
       " ('=_png&auto', '=_webp&s_='),\n",
       " ('aid_polish_government_launched', 'dedicated_site'),\n",
       " ('ready_arrival_reception_points', 'ready_border'),\n",
       " ('ready_border', 'shelter_food_medical_legal'),\n",
       " ('shelter_food_medical_legal', 'aid_polish_government_launched'),\n",
       " ('shelter_food_medical_legal', 'dedicated_site'),\n",
       " ('=_pjpg&auto', '=_webp&s_='),\n",
       " ('seek_asylum_polish_border', 'ready_border'),\n",
       " ('seek_asylum_polish_border', 'ready_arrival_reception_points'),\n",
       " ('russia_backed_trolls', 'polish_border_closed_lie'),\n",
       " ('polish_border_closed_lie', 'seek_asylum_polish_border'),\n",
       " ('russia_backed_trolls', 'seek_asylum_polish_border'),\n",
       " ('polish_border_closed_lie', 'ready_arrival_reception_points'),\n",
       " ('share_information', 'know_seeking'),\n",
       " ('need_passport_visas', \"suspended_don't_need\"),\n",
       " ('russian', 'soldiers'),\n",
       " ('help_ua.gov.plplease', 'know_seeking'),\n",
       " ('aid_polish_government_launched', 'help_ua.gov.plplease'),\n",
       " ('dedicated_site', 'help_ua.gov.plplease'),\n",
       " ('news_spread_likely', 'russia_backed_trolls'),\n",
       " ('polish_border', 'need_passport_visas'),\n",
       " ('help_ua.gov.plplease', 'share_information'),\n",
       " ('news_spread_likely', 'polish_border_closed_lie'),\n",
       " ('x200b;https://preview.redd.it', '=_png&auto'),\n",
       " ('dedicated_site', 'share_information'),\n",
       " ('speak', 'russian'),\n",
       " ('polish_border', \"suspended_don't_need\"),\n",
       " ('speak', 'ukrainian')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change input arguments\n",
    "ukraine_tokens.collocation_list(num=30, window_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ff5e8-247a-474b-a30f-3c2090205c64",
   "metadata": {},
   "source": [
    "### Word Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5185bce-1517-4dfa-95d7-8855690fe0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ukraine_tokens.dispersion_plot([\"Russian-Ukrainian War\", \"Question\", \"Discussion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6b1719c-096f-406e-9a2e-562af3845adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##MJ: Tried different words, but still doesn't show anything?\n",
    "ukraine_tokens.dispersion_plot([\"Russian\", \"Ukrainian\", \"War\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96c6c06-ada2-4bfa-962c-fa75d2bdd65e",
   "metadata": {},
   "source": [
    "### Similar Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d4f9cff-fb3c-40f5-a969-9bfe5834d5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like ukraine friends currently wife know time looking kiev nt hey\n",
      "people language supposed ukrainian visiting russian going want guys\n"
     ]
    }
   ],
   "source": [
    "ukraine_tokens.similar('partner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114a54c7-5e98-43c0-bc39-217ef809e1bf",
   "metadata": {},
   "source": [
    "### Common Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "433b9523-7049-48e7-b6a8-1ae6cde872b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No common contexts were found\n"
     ]
    }
   ],
   "source": [
    "ukraine_tokens.common_contexts(['mom', 'dad'])  ##MJ: We need to change the input to match our data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c5da1c-7afb-4e80-9cfc-66808a091657",
   "metadata": {},
   "source": [
    "## 2.4 Incorporating Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e6865ab5-ef1d-4d1b-a55f-51cc0f8a405f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2008-04-08 05:21:54')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(1207632114, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "42b4b273-9f4a-4b76-81b8-fc108177b4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idint</th>\n",
       "      <th>idstr</th>\n",
       "      <th>created</th>\n",
       "      <th>created_datetime</th>\n",
       "      <th>nsfw</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>score</th>\n",
       "      <th>distinguish</th>\n",
       "      <th>textlen</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>flair_text</th>\n",
       "      <th>flair_css_class</th>\n",
       "      <th>detect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26781072</td>\n",
       "      <td>t3_fy0eo</td>\n",
       "      <td>1299351508</td>\n",
       "      <td>2011-03-05 18:58:28</td>\n",
       "      <td>0</td>\n",
       "      <td>margys</td>\n",
       "      <td>Мам, а когда я выросту, ты постареешь?...</td>\n",
       "      <td>Сегодня моя золотая птичка снова задалась вопр...</td>\n",
       "      <td>сегодня моя золотая птичка снова задалась вопр...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26795140</td>\n",
       "      <td>t3_fyb9g</td>\n",
       "      <td>1299397232</td>\n",
       "      <td>2011-03-06 07:40:32</td>\n",
       "      <td>0</td>\n",
       "      <td>pozhaluista</td>\n",
       "      <td>Does the /r/ Ukraine have anyone here? Hello?</td>\n",
       "      <td>Seems quiet.</td>\n",
       "      <td>quiet</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29482904</td>\n",
       "      <td>t3_hjx5k</td>\n",
       "      <td>1306343697</td>\n",
       "      <td>2011-05-25 17:14:57</td>\n",
       "      <td>0</td>\n",
       "      <td>visarun</td>\n",
       "      <td>Does immigration in Simferpol check whether th...</td>\n",
       "      <td>I have stayed 70 days and then 80 days out of ...</td>\n",
       "      <td>stayed days days days know borispol pretty str...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      idint     idstr     created    created_datetime  nsfw       author  \\\n",
       "0  26781072  t3_fy0eo  1299351508 2011-03-05 18:58:28     0       margys   \n",
       "1  26795140  t3_fyb9g  1299397232 2011-03-06 07:40:32     0  pozhaluista   \n",
       "2  29482904  t3_hjx5k  1306343697 2011-05-25 17:14:57     0      visarun   \n",
       "\n",
       "                                               title  \\\n",
       "0         Мам, а когда я выросту, ты постареешь?...    \n",
       "1      Does the /r/ Ukraine have anyone here? Hello?   \n",
       "2  Does immigration in Simferpol check whether th...   \n",
       "\n",
       "                                            selftext  \\\n",
       "0  Сегодня моя золотая птичка снова задалась вопр...   \n",
       "1                                      Seems quiet.    \n",
       "2  I have stayed 70 days and then 80 days out of ...   \n",
       "\n",
       "                                              lemmas  score distinguish  \\\n",
       "0  сегодня моя золотая птичка снова задалась вопр...      0         NaN   \n",
       "1                                              quiet     10         NaN   \n",
       "2  stayed days days days know borispol pretty str...      0         NaN   \n",
       "\n",
       "   textlen  num_comments flair_text flair_css_class detect  \n",
       "0      204             0        NaN             NaN     en  \n",
       "1       13            24        NaN             NaN     en  \n",
       "2      223             1        NaN             NaN     en  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new colum with date and time\n",
    "df.insert(loc=3, column='created_datetime', value=pd.to_datetime(df['created'], unit='s'))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40b11a55-d78a-4aed-8e17-76308450b9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011,\n",
      "            ...\n",
      "            2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022],\n",
      "           dtype='int64', name='created_datetime', length=16646)\n"
     ]
    }
   ],
   "source": [
    "#create new variables years\n",
    "years = pd.DatetimeIndex(df['created_datetime']).year\n",
    "print(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "07cc83cc-773d-449a-aad5-4d423341fc05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#before 2013\n",
    "df_2013 = df.loc[(years <= 2013), :]\n",
    "len(df_2013)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c83b1ca-e8e9-4e75-99a4-8ff3e1028123",
   "metadata": {},
   "source": [
    "## Q. How to add another contraction after 2014?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2a7e2499-fb0e-4281-964b-ea5ec09692a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16520"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after 2013 & before 2022\n",
    "df_b2022 = df.loc[(years <= 2022) & (years >=2013), :]\n",
    "len(df_b2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b52fbef4-c3a8-4382-b987-bed7c22792b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9383"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after 2022\n",
    "df_a2022 = df.loc[(years >= 2022), :]\n",
    "len(df_a2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb87bb14-d9c3-457d-afd3-2ba399119c78",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2332242677.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [58]\u001b[1;36m\u001b[0m\n\u001b[1;33m    x=months_array,\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# visualize data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "sns.set(rc={'figure.figsize': (7, 5)})\n",
    "\n",
    "p = sns.histplot(\n",
    "    ##data=df_2021, ##MJ: changed the dataframe\n",
    "    data=df_a2022\n",
    "    x=months_array,\n",
    "    hue=\"flair_css_class\",\n",
    "    multiple=\"stack\")\n",
    "\n",
    "plt.xticks(rotation=70)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eff5dd1",
   "metadata": {},
   "source": [
    "# Term Frequency-Inverse Document Frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e9cab95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aita = pd.read_csv('ukraine_lemmas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1f63fdb3-d057-4e2a-a861-e1d34c94281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Settings that you use for count vectorizer will go here\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.85,\n",
    "                                   decode_error='ignore',\n",
    "                                   stop_words='english',\n",
    "                                   smooth_idf=True,\n",
    "                                   use_idf=True)\n",
    "\n",
    "# Fit and transform the texts\n",
    "tfidf = tfidf_vectorizer.fit_transform(aita['lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fac033e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place TF-IDF values in a DataFrame\n",
    "df = pd.DataFrame(tfidf.todense(), columns=tfidf_vectorizer.get_feature_names_out().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5d01caf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>00012340</th>\n",
       "      <th>00013962</th>\n",
       "      <th>000147123</th>\n",
       "      <th>0001bdb4ca60e95849a09137ac9082af2b67</th>\n",
       "      <th>00032106payee</th>\n",
       "      <th>000eur</th>\n",
       "      <th>000l</th>\n",
       "      <th>000ruble</th>\n",
       "      <th>...</th>\n",
       "      <th>𝐬𝐞𝐜𝐨𝐧𝐝</th>\n",
       "      <th>𝐭𝐡𝐞</th>\n",
       "      <th>𝐭𝐡𝐢𝐫𝐝</th>\n",
       "      <th>𝐰𝐚𝐫</th>\n",
       "      <th>𝔉𝔢𝔡𝔢𝔯𝔞𝔩</th>\n",
       "      <th>𝙹ᒲ</th>\n",
       "      <th>𝙹リ</th>\n",
       "      <th>𝙹リℸ</th>\n",
       "      <th>𝙹リ𝙹</th>\n",
       "      <th>𝙹ꖎ𝙹</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 69564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     00  000  00012340  00013962  000147123  \\\n",
       "0   0.0  0.0       0.0       0.0        0.0   \n",
       "1   0.0  0.0       0.0       0.0        0.0   \n",
       "2   0.0  0.0       0.0       0.0        0.0   \n",
       "3   0.0  0.0       0.0       0.0        0.0   \n",
       "4   0.0  0.0       0.0       0.0        0.0   \n",
       "5   0.0  0.0       0.0       0.0        0.0   \n",
       "6   0.0  0.0       0.0       0.0        0.0   \n",
       "7   0.0  0.0       0.0       0.0        0.0   \n",
       "8   0.0  0.0       0.0       0.0        0.0   \n",
       "9   0.0  0.0       0.0       0.0        0.0   \n",
       "10  0.0  0.0       0.0       0.0        0.0   \n",
       "11  0.0  0.0       0.0       0.0        0.0   \n",
       "12  0.0  0.0       0.0       0.0        0.0   \n",
       "13  0.0  0.0       0.0       0.0        0.0   \n",
       "14  0.0  0.0       0.0       0.0        0.0   \n",
       "15  0.0  0.0       0.0       0.0        0.0   \n",
       "16  0.0  0.0       0.0       0.0        0.0   \n",
       "17  0.0  0.0       0.0       0.0        0.0   \n",
       "18  0.0  0.0       0.0       0.0        0.0   \n",
       "19  0.0  0.0       0.0       0.0        0.0   \n",
       "\n",
       "    0001bdb4ca60e95849a09137ac9082af2b67  00032106payee  000eur  000l  \\\n",
       "0                                    0.0            0.0     0.0   0.0   \n",
       "1                                    0.0            0.0     0.0   0.0   \n",
       "2                                    0.0            0.0     0.0   0.0   \n",
       "3                                    0.0            0.0     0.0   0.0   \n",
       "4                                    0.0            0.0     0.0   0.0   \n",
       "5                                    0.0            0.0     0.0   0.0   \n",
       "6                                    0.0            0.0     0.0   0.0   \n",
       "7                                    0.0            0.0     0.0   0.0   \n",
       "8                                    0.0            0.0     0.0   0.0   \n",
       "9                                    0.0            0.0     0.0   0.0   \n",
       "10                                   0.0            0.0     0.0   0.0   \n",
       "11                                   0.0            0.0     0.0   0.0   \n",
       "12                                   0.0            0.0     0.0   0.0   \n",
       "13                                   0.0            0.0     0.0   0.0   \n",
       "14                                   0.0            0.0     0.0   0.0   \n",
       "15                                   0.0            0.0     0.0   0.0   \n",
       "16                                   0.0            0.0     0.0   0.0   \n",
       "17                                   0.0            0.0     0.0   0.0   \n",
       "18                                   0.0            0.0     0.0   0.0   \n",
       "19                                   0.0            0.0     0.0   0.0   \n",
       "\n",
       "    000ruble  ...  𝐬𝐞𝐜𝐨𝐧𝐝  𝐭𝐡𝐞  𝐭𝐡𝐢𝐫𝐝  𝐰𝐚𝐫  𝔉𝔢𝔡𝔢𝔯𝔞𝔩   𝙹ᒲ   𝙹リ  𝙹リℸ  𝙹リ𝙹  𝙹ꖎ𝙹  \n",
       "0        0.0  ...     0.0  0.0    0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1        0.0  ...     0.0  0.0    0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2        0.0  ...     0.0  0.0    0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3        0.0  ...     0.0  0.0    0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4        0.0  ...     0.0  0.0    0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "5        0.0  ...     0.0  0.0    0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "6        0.0  ...     0.0  0.0    0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "7        0.0  ...     0.0  0.0    0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "8        0.0  ...     0.0  0.0    0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "9        0.0  ...     0.0  0.0    0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "10       0.0  ...     0.0  0.0    0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "11       0.0  ...     0.0  0.0    0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "12       0.0  ...     0.0  0.0    0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "13       0.0  ...     0.0  0.0    0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "14       0.0  ...     0.0  0.0    0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "15       0.0  ...     0.0  0.0    0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "16       0.0  ...     0.0  0.0    0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "17       0.0  ...     0.0  0.0    0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "18       0.0  ...     0.0  0.0    0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "19       0.0  ...     0.0  0.0    0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[20 rows x 69564 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6be12635",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ukraine                578.853722\n",
       "https                  391.731019\n",
       "ukrainian              343.911766\n",
       "russian                319.397661\n",
       "know                   305.674112\n",
       "                          ...    \n",
       "1498974101066727427      0.001169\n",
       "khiv                     0.001169\n",
       "casusbellii              0.001169\n",
       "cqv2ej_nq                0.001169\n",
       "1498985949728022529      0.001169\n",
       "Length: 69564, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Highest TF-IDF values across documents\n",
    "df.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3d3b7c",
   "metadata": {},
   "source": [
    "# Using TF-IDF to find Similar Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "85ad5cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_idx = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ced8585b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hey /r/ukraine!\\n\\nLong story short, I'm researching Ukrainian-American history, i.e. immigration to America and I'm not finding any good, solid sources. I was wondering if /r/ukraine would know of any good places to find information on this topic? For reference, my best source so far is a book called Ukrainian Immigrants in New York by Halyna Lemekh; all internet sources have failed.\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aita['selftext'].iloc[doc_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "52d57e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sources            0.304821\n",
       "lemekh             0.296862\n",
       "halyna             0.284857\n",
       "story_short        0.264335\n",
       "immigrants         0.209686\n",
       "                     ...   \n",
       "googlemaps         0.000000\n",
       "googler            0.000000\n",
       "googles            0.000000\n",
       "googletranslate    0.000000\n",
       "𝙹ꖎ𝙹                0.000000\n",
       "Name: 25, Length: 69564, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[doc_idx].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "919a7781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16646, 16646)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarities = cosine_similarity(tfidf)\n",
    "similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3575a549",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_df = pd.DataFrame({\n",
    "    'text': aita['selftext'].values,\n",
    "    'score': similarities[doc_idx]}).sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d21649cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hey /r/ukraine!\\n\\nLong story short, I'm researching Ukrainian-American history, i.e. immigration to America and I'm not finding any good, solid sources. I was wondering if /r/ukraine would know of any good places to find information on this topic? For reference, my best source so far is a book called Ukrainian Immigrants in New York by Halyna Lemekh; all internet sources have failed.\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_df['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "27d80b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I've been trying to find good sources for Ukrainian Folklore and fairy tales for research, though Google searches have not led me to any sources I feel comfortable going off of. Does anyone know any good sources I could use?\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_df['text'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "65c289a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Back to ask another question, what would be good, accurate and well written history book on the Ukraine? Or even books that tell the history of different parts of ukraine history, like people or places?'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_df['text'].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2942d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
